# Fast Swap

**Can Far Memory Improve Job Throughput?**


[출처] EuroSys ’20, April 27–30, 2020, Heraklion, Greece

> RDMA


## 1. 소개

최근 머신러닝과 같은 메모리 집약적 앱의 인기 증가는 컴퓨터 클러스터의 메모리 요구에 대한 수요가 급격히 증가시키고 있다. 동시에, 무어의 법칙 때문에 DRAM 제조사는 메모리가 크면서 비용이 적은 메모리를 제조하기에 힘 쓰고 있다.



최근 연구가 활발한 `memory disaggregation`은 더 이상 앱이 로컬 메모리에 제한적이지 않게 해준다. 이것은 메모리 장벽을 넘어 응용이 공유되는 메모리로 확장될 수 있도록 지원한다. 특히, **사용되지 않고 있는 다른 클러스터의 메모리를 활용**한다는 점에서 활용성이 매우 뛰어나다.



하지만 `far memory`를 사용하는 것은 두 가지 문제가 있다. 첫 번째는 현재 스와핑 메커니즘은 디스크를 기준으로 구현되어 있기 때문에 far memory 접근을 위한 설계가 필요하다는 것이다.



이를 극복하기 위해, 이 논문에서는 **Fastswap**을 제시한다. `Fastswap`은 linux control group과 직접 소통함으로써 로컬 메모리 할당을 지원한다. 또한, 페이지를 fetch 하기 위한 경로를 분리된 큐로 구현함으로써 HOL 블로킹을 방지한다. 그리고 중요한 페이지 연산에 대한 경쟁을 위해 polling하는 방식과 전용 CPU를 통한 메모리 복원을 오프로딩 함으로써 경로에 대한 지연을 감소시킨다.



두 번째 문제는 로컬 메모리와 far memory 사이에서 작업의 메모리 요구를 어떻게 분리할 것인지 결정하는 문제이다. `Fastswap`에서는 이 문제를 **Fare memory-aware cluster scheduler**를 구현함으로써 해결하고 있다.



새로운 작업이 도착하면, 스케줄러는 로컬 메모리가 공간을 초기화하기에 충분하지 않다면 서버에 할당할 수 있다. 또한, 몇몇 존재하는 작업을 서버에 위치함으로써 로컬 메모리 사용을 줄이고, far memory를 사용함으로써 전체 작업이 충분한 메모리 공간을 가질 수 있도록 보장한다. 그리고 far memory의 사용은 더 많은 작업이 동시에 수행될 수 있도록 한다.



**CFM(Fastswap + cluster scheduler)**를 통해 cluster-wide far memory를 지원할 수 있다. 하지만 far memory의 사용이 메모리 문제의 만병통치약이 될 수는 없다. 예를 들어 메모리 요구가 사용가능한 메모리보다 큰 경우, 공유되는 서버의 far memory 수를 늘리는 것보다 로컬 메모리를 늘리는 것이 더 좋은 성능을 보인다. 하지만 두 가지 특정 상황에서 far memory의 사용이 큰 장점을 보인다.



1. workload가 메모리 집약적이면 (코어 이용보다 메모리 이용량에서 더욱 병목적일 때), 컴퓨팅 노드를 far memory로 전환하는 것은 처리량을 많이 증가시킬 수 있다.

2. 연산자가 메모리가 부족하여 메모리를 더 필요로 할 때, 서버에 메모리를 증가하는 것을 통해 병렬성을 증가시킴으로써 성능을 향상시킬 수 있다.



## 2. 배경

데이터 센터의 앱에서 메모리 요구가 점자척으로 증가함으로써, 메모리가 데이터 센터를 구현하는 비용의 큰 부분을 차지하게 됐다. 결과적으로 클러스터는 데이터 센터에 어떻게 메모리를 제공할 지 선택하는 것에 어려움을 겪고 있다.



### 2.1 Memory Provisioning



![1](https://user-images.githubusercontent.com/56579239/189981103-54bb6b60-4b56-4ddf-a1e4-81787fb0bd0c.png)



로컬 메모리는 다소 큰 단위로 제공된다. 위의 그림처럼 최근의 Intel에서 제공하는 2소켓 메모리 구조를 살펴보면, 총 24개의 DIMM 슬롯을 제공한다. 그리고 각각의 메모리 슬롯은 2GB, 4GB, 8GB, 16GB와 같은 크기로 이루어져 있다. 동일한 서버에서 임의의 수의 DIMM 조합은 비효율적으로 활용된다. 메모리가 인터리빙 되는 프로세스의 동작 방식 때문에, 불균형한 메모리 구조는 메모리 대역폭을 대폭 낮춘다. 



완전한 메모리 대역폭을 제공하기 위해 메모리 밸런싱을 하려면 다음과 같은 가이드라인을 따라야 한다.

1. 모든 메모리 채널은 같은 메모리 수를 가져야 한다.

2. 메모리 컨트롤러는 같은 구조의 DIMM을 가져야 한다.

따라서 모든 메모리 `slot 0`은 같은 메모리 용량을 가져야하며, 모든 `slot 1` 또한 같은 용량을 가져야 한다.



균형있는 메모리 구조를 달성하는 것은 초기에 메모리를 제공할 때 세분성을 제한하고, 메모리 요구가 바뀔 때 메모리를 업그레이드 하는 것에 있어서 제한적이다. 예를 들어, 192GB의 메모리가 한 채널 당 16GB DIMM으로 이루어져 있을 때, 메모리를 최소한으로 업그레이드 하려면 한 채널 당 4GB씩 12개를 더해야 한다. 여기서 또 최소한으로 업그레이드 하려면, 4GB DIMM을 모두 제거하고 8GB로 교체해야 한다.



그래서 시스템 당 하나의 메모리만 제공할 수 있는 경우, 메모리 구조에 대한 제약 때문에 메모리 대역폭이 대폭 감소된 상태로 연산을 수행하거나 메모리 용량을 매우 크게 증가시켜서 변화하는 메모리 요구량에 맞추지 못 해 메모리 과소/과다 공급이 이루어진다. 



### 2.2 Deployment Scenarios



`Fastswap`은 현재 시스템의 점진적인 개발에 포커스를 두고 있다. 현재 데이터 센터는 모든 DIMM 슬롯을 채우려는 경향이 있다. 이것은 메모리 유닛 당 비용과 DIMM 용량을 증가시키기 때문에 경제적이다. 그래서 가장 저렴하게 주어진 양의 메모리를 제공하는 방법은 이용 가능한 DIMM 슬롯을 모두 사용하는 것이다



소규모에서 중간 규모의 데이터 센터 연산자는 전체 시스템을 한 번에 업그레이드 하는 것을 선호하고, 로컬 메모리의 일부를 업그레이드 하는 것을 고려하지 않는다. 그 이유는 두 가지인데 다음과 같다.

1. 운영 상의 이유로 다른 종류의 메모리를 관리하는 것을 어렵다.

2. far memory는 머신의 정적 메모리 파티셔닝으로 인해 메모리 초과/미달 공급을 피하는 것이 좋다.



far memory는 클러스터 처리량 개선의 잠재력이 있는 반면에, 각각의 작업을 위한 느린 런타임의 비용으로 여겨진다. 예를 들어, far memory는 metric이 작업 처리량의 주작업인 응용에게 잘 맞지만, 지연 시간에 민감한 응용에는 맞지 않는다.



## 3. CFM



**CFM**의 목표는 전용 메모리 서버의 **far memory**를 활용하여 클러스터가 종단간 작업 처리량을 개선시키도록 하는 것이다. 이를 통해, 종단간 작업의 개선과 작업 리스트를 수행하는데 걸리는 시간을 개선시키는 것에 포커스를 두고 있다. 



### 3.1 Approach

<h4> Swapping </h4>

응용은 far memory를 두 가지 방법으로 활용할 수 있다: 응용의 수정 없이 투명하게 사용하거나 사용자 정의 API를 통한 암시적인 호출을 통해 사용한다. 사용자 >    정의 API를 사용하는 방법은 성능을 더욱 높일 수 있겠지만, 비현실적인 방법이다. 왜냐하면 많은 기종의 의존성을 충족 시키면서도 많은 워크로드를 수행하는 것은 힘든 일이기 때문이다. 따라서 사용자 정의 API 대신에 CFM은  `Infiniswap`처럼 기존의 가상 메모리를 활용하는 스와핑 기법을 통해 far memory를 활용하는 방법을 사용한다.



CPU가 현재 물리 메모리에 존재하지 않는 페이지의 메모리 주소에 접근하면, 페이지 폴트가 발생하고 페이지 폴트 핸들러는 스왑 스페이스로부터 로컬 메모리로 페이지를 가져온다. 일반적으로 스왑 스페이스는 디스크에 상주하고 있으며, 워크로드에 poorly한 성능과 오버헤드로 인해 millisecond-scale의 접근 시간을 초래하게 된다. 

그러나 스와핑이 millisecond-scale의 지연시간을 초래하는 것이 아니다. 그리고 요즘의 microsecond-scale의 네트워크 지연시간 덕분에 네트워크를 통한  far memory로의 스와핑은 디스크로의 스와핑보다 오히려 더 좋은 성능을 보인다.



<h4>Cgroups</h4>

CFM은 리눅스에서 제공하는 control groups를 사용하여 로컬 메모리에 대한 작업별 제한을 강화한다. Cgroups는 프로세스가 물리 메모리에 할당되는 양을 제어하고, CFM은 스왑 시스템을 활용하여 초과되는 메모리를 far memory에 유지한다.



<h4>RDMA</h4>

CFM은 RDMA를 원격 서버의 메모리에 낮은 접근 지연 시간으로 접근하기 위해 활용한다. CFM은 원격 서버의 CPU 사용 없이 메모맃에 접근할 수 있는 one-sided `read`, `write` 연산을 사용한다. 일반적으로 RDMA 연산은 로컬 `queue pair`로 보내지고, 로컬의 RDMA NIC에 의해 수행된다. 한 번 수행이 완료되면 NIC은 `completion queue`에 완료 연산을 보낸다. `completion queue`는 완료 연산이 도착하면 인터럽트를 발생시키거나 폴링 주기를 기다리도록 조정될 수 있다. 

RDMA는 원격 서버와 로컬의 운영체제를 바이패스한다. 그러나 RDMA는 드라이버가 사용할 수 있도록 커널 API를 제공한다. (CFM은 스와핑 페이지를 네트워크로 보내기 위해 이 API를 활용한다)



### 3.2 Challenges and Contributions

원격 메모리에서 클러스터 규모의 이점을 실현하는 데는 두 가지 주요 과제가 있다: 원격 메모리를 빠르게 전환할 수 있도록 하는 것과 로컬 및 원격 메모리에서 작업을 스케줄링하는 방법을 결정하는 것.



<h4>Fast Swapping</h4>

RDMA 스왑 장치와 같은 접근법은 다음과 같은 세 가지 이유로 요즘 응용이 요구하는 높은 성능을 유지할 수 없다.

1. OS는 페이지 폴트가 발생하면 몇 개의 페이지를 더 가져오는 방식으로, 다음에 발생할 페이지 폴트의 I/O 지연시간을 없앤다. 그러나 리눅스에서 요구 페이지는 윈도우 어디에나 존재할 수 있는데, 현재 시스템은 모든 페이지를 CPU 당 single queue pair (더욱 안 좋을 땐, 모든 스왑 시스템을 하나의 single queue pair를 사용) 사용한다. 그래서 요구 페이지가 prefetch 페이지보다 뒤에 있을 수 있다. 

   하나의 페이지를 가져오는 시간은 메모리에 할당하는 시간 때문에 microseconds가 소비된다. 그래서 리눅스는 prefetch size를 8로 정의하고 있는데, HOL 블로킹이 요구 페이지의 fetching을 10 microseonds를 지연시킬 수 있다.

2. RDMA를 통해 스왑하는 시스템은 RDMA 연산이 완료됐음을 CPU에게 인터럽트를 통해 알린다. 이 인터럽트 처리는 페이지 폴트 핸들러가 응용에게 페이지를 리턴하기 전까지 `critial path`에서 발생한다. 그리고 이것은 10μs 나 더 많은 시간을 페이지 폴트 처리에 지연되게 한다.

3. 폴트 페이지를  로컬 메모리로 가져온 후, 운영체제는 메모리 카운터를 증가시킴으로써 새 페이지를 cgroup에 추가한다. 만약 cgroup 메모리가 초과하게 되면, 초과 페이지는 원격 메모리로 다시 스왑아웃한다. 리눅스에서 시스템 측면의 스왑아웃과 다르게, cgroups의 메모리 복원은 페이지 폴트 핸들러를 종료하기 전에 응용에 직접 반환하는 방식으로 직접적으로 이루어진다. 그래서 전체 프로세스의 복원(찾은 페이지를 복원하고 스왑 디바이스에 쓰고 재사용을 위해 커널에 페이지를 반환하는)은 페이지 폴트를 지연시킨다.

CFM은 이 세 가지를 극복하여  Infiniswap보다 낮은 접근 지연 시간과 높은 처리량을 성취하는 `fast swap`을 소개한다.



### 3.2.2 Cluster Scheduling

현재 존재하는 스케줄러들은 코어, 메모리 등의 자원을 공유하여 작업을 스케줄링 함으로써 클러스터 자원을 효율적으로 공유한다. 그러나 이 스케줄러들은 원격 서버를 고려하지 못 하여서 메모리가 로컬과 원격 메모리에 동적으로 나뉘는 작업을 스케줄링 하지 못 한다. 그리고 멀티 큐를 통해 동일한 장치에 여러 작업을 공유하는 로컬 메모리를 어떻게 최적으로 할당할 지 모른다.

CFM은 장치에 작업을 할당할 때 원격 메모리를 고려하고 소요 시간을 최적화하기 위해 다른 작업 간에 로컬 메모리를 분할하는 방법을 결정하는 중앙 집중식 원격 메모리 인식 스케줄러를 제안한다.



## 4 Fastswap


![2](https://user-images.githubusercontent.com/56579239/189981132-83b1f556-743f-49b2-bc05-392cf09a8d3f.png)



위의 그림은 Fastswap의 전체적인 구조와 어떻게 현재 OS의 컴포넌트 위에서 성능을 향상시키는 지 보여준다. 기존의 연구들은 단순히 RDMA를 스왑 디바이스로써 백엔드에 노출시키는 것에 노력했다면, `Fastswap`은 더 높은 스와핑 성능을 위해서는 페이지 폴트 핸들러와 스왑 시스템, cgroup 메모리 컨트롤러의 수정이 필요한 것을 발견했다. 

Fastswap은 300줄의 4.11 버전의 리눅스 커널 코드 수정과 1200 줄의 새 디바이스 드라이버로 구현되었다.



많은 시스템은 millisecond-scale의 지연 시간 향상에 집중하지만, Fastswap은 microsecond-scale의 스와핑을 가능하게 한다. Fastswap의 많은 메커니즘은 프로그램 수행이 중단되는 동안에 발생하기 때문에 절약되는 microsecond는 응용에게 컴퓨팅 시간으로 사용된다.



### 4.1 RDMA Backend

Fastswap에서는 OS가 RDMA 백엔드를 사용하여 RDMA NIC과 상호작용한다. 위의 그림에서처럼, 백엔드는 스왑 연산의 타입에 따라 사용된다: page faults, prefetches, memory reclaim. 이전의 연구는 RDMA 백엔드를 블록 디바이스처럼 사용했다면, Fastswap은 `Frontswap` 인터페이스를 사용한다. Frontswap은 일반적인 블록 I/O 연산이 아니라 페이지 단위의 스와핑을 위해 설계되었고, 스왑 연산이 완료되는 동안 다른 작업의 context switch를 최소화한다.



<h4>Queue Pairs</h4>

RDMA는 NIC의 프로세싱 유닛에 의해 순서대로 수행되는 주어진 큐페어로 요청한다. 만약 다른 종류의 스왑 연산이 큐를 공유한다면(폴트 페이지를 읽고 스왑아웃 페이지를 쓰는 연산), 중요한 연산은 덜 중요한 프리페칭 연산 뒤에 큐잉 될 것이다. Fastswap은 CPU 당 두 개의 RDMA 큐페어를 사용함으로써 이런 종류의 HOL 블로킹을 피한다.

이런 연산을 두 개의 큐 페어로 분리시키는 것은 Fastswap이 연산을 다르게 처리할 수 있도록 도와준다. Fastswap RDMA 백엔드는 프리페칭 페이지의 완료 연산을 위해 인터럽트 방식을 사용하고 중요한 연산에 대해 폴링 방식을 사용한다. 



<h4>Frontswap interface</h4>

Frontswap은 연산의 완료가 동기적으로 처리된다고 가정하기 때문에, frontswap의 연산이 완료되어야 수행 제어를 swap system으로 반환한다. 그래서 중요한 연산과 중요하지 않은 연산을 구분하는 메커니즘을 제공하지 않는다. 그래서 Fastswap은 RDMA 백엔드가 적절한 큐페어로 요청하도록 조정함으로써 frontswap 인터페이스가 중요한 연산과 중요하지 않은 연산을 구분할 수 있도록 요구한다. Fastswap의 frontswap 인터페이스 수정을 통해, 두 가지 연산은 RDMA 요청을 생성한 후 모두 즉시 반환된다. 중요한 연산에 대한 완료 처리는 폴링하고 그렇지 않은 연산은 인터럽트를 트리거 하는 방식으로 스왑 시스템을 수정하였다.



### 4.2 Page Fault Handler

Fastswap은 페이지 폴트 핸들러를 두 가지 핵심 방식으로 수정했다.

- 폴트 페이지와 프리페칭 페이지를 다르게 처리한다.
- 폴트 페이지를 먼저 읽은 후에 프리페칭 윈도우에 남아있는 나머지 페이지를 읽는다.

모든 읽기 연산 후에, Fastswap은 폴프 페이지를 폴링한다. 폴트 페이지를 먼저 요청함으로써, 프리페칭 페이지를 위한 메모리 할당 지연시간과 프리페칭 RDMA 요청 시간을 극복할 수 있다. 아래 그림은 Fastswap이 어떻게 폴트 페이지와 프리페칭을 다루는 지 보여준다.



![3](https://user-images.githubusercontent.com/56579239/189981157-7cd1742b-206a-4307-9239-1e6ea5f53e36.png)



폴트 페이지와 프리페칭 페이지를 다르게 처리하는 것은 누락된 프리페치의 비용을 최소화 한다. 예를 들어 F<sub>1</sub> 주소에 페이지 폴트가 발생하면 연관된 세트의 프리페칭 페이지 P<sub>1</sub>와 함께 읽기 요청을 보낸다. 그 다음 F<sub>2</sub> 주소에 두 번째 페이지 폴트가 발생하게 되면, 기존의 시스템은 P<sub>1</sub> 페이지의 읽기 연산이 완료되기를 기다려야 한다. 하지만 Fastswap은 프리페칭을 기다리지 않고도 폴트 페이지를 바로 가져온다.



### 4.3 Memory Reclaim

Fastswap은 프로세스가 사용할 수 있는 로컬 메모리의 양을 초과하지 않도록 메모리를 복구한다. Fastswap은 메모리 복구를 cgroup 메모리 컨트롤러를 수정함으로써 페이지 폴트를 처리하는 임계 경로로 옮겼다.

일반적으로 메모리 복구는 cgroup의 메모리가 제한을 넘어 커지거나 cgroup의 메모리 제한이 줄어들 때 필요하다. Fastswap에서는 페이지 폴트가 원격 메모리에서 로컬 메모리로 페이지를 가져오거나 프로세스가 추가적으로 메모리를 할당하면 cgroup의 메모리가 증가한다. 반면에 메모리 제한은 원격 메모리 스케줄러가 프로세스의 추가를 위해 메모리를 적합시킬 때 제한이 줄어든다.



보통 폴트 페이지를 가져오면 메모리 컨트롤러는 페이지를 cgroup에 추가시킨다. 그래서 컨트롤러가 cgroup이 메모리 제한보다 많은 용량을 차지하지 않는지 체크한다. 만약 메모리를 초과하는 페이지가 있으면, 페이지는 원격 메모리로 보내지며 직접적으로 메모리 복구가 이루어진다. 직접적인 메모리 복구는 페이지 폴트 핸들러에 의해 이루어지며, CPU가 user space로 반환하고 워크로드를 게속 수행하는 것을 방지한다.



응용이 원격 메모리에 그들의 50% 메모리를 사용하여도 리눅스 커널의 메모리 복구는 커널의 62~85%를 소비한다. 이 소비를 줄이기 위해, 노드가 원격 메모리를 사용할 때 메모리 컨트롤러가 메모리 복구를 전용 CPU 코어로 오프로딩 한다(`offloaded reclaim`). 메모리 복구를 오프로딩 하는 것은 CPU가 메모리 복구에 시간을 소비하지 않고 user spacre로 페이지 폴트를 반환할 수 있도록 한다. 



메모리 복구는 모든 상황에 적합하지는 않다. 예를 들어, 큰 메모리 할당이나 메모리 제한이 크게 줄어드는 상황에서 메모리 복구를 오프로딩 하는 것은 병목이 발생할 수 있다. 왜냐하면 메모리 복구는 CPU를 통해 공유되기 때문이다.



cgroups가 메모리 할당을 초과하는 것을 방지하기 위해, Fastswap은 각각의 cgroups에게 threshold 메모리를 준다. cgroup이 처음 메모리 제한에 도달하게 되면, 메모리 컨트롤러는 메모리 복구를 오프로딩 한다. 메모리 복구가 바빠서 복구를 충분히 서비스하지 못 하면, cgroup을 요청하는 메모리가 계속 증가할 것이다. 한 번 메모리 제한을 초과하게 되면, 페이지 폴트 핸들러는 직접 복구를 잘 수행할 것이다. 이 개런티는 cgroups이 threshold보다 초과하지 않을 때 이루어진다.



메모리 복구가 직접 이루어지든 오프로딩 되던 간에, 원격 메모리로 페이지가 스왑 아웃될 때, OS는 완료를 폴링한다. 원격 메모리로의 쓰기 연산이 완료된 후에, 페이지가 완전히 복구된다.그래서 cgroup 메모리 할당은 줄어들고, 커널은 페이지를 재사용할 수 있다. 메모리 복구가 배치에 의해 완료되면, 쓰기 인터럽트를 사용하는 것은 복구를 지연시키고 더 많은 페이지 복구를 요구할 것이다. 폴링을 사용하면, 쓰기 연산  완료 후, cgroup은 메모리 카운터를 즉시 줄인다.



## 5. Far Memory-Aware Scheduler

Fastswap의 스케줄러는 `Bin-Packing` 알고리즘을 사용하여 작업이 필요한 메모리를 할당하고, 로컬 메모리 대신 원격 메모리를 사용 함으로써 융퉁성을 제공한다. 따라서 각 노드에서 메모리가 리소스를 필요로할 때 적정한 양을 제공할 수 있음으로써 처리량을 직관적으로 늘린다. 하지만, 원격 메모리의 사용은 각각의 작업의 처리 속도를 느리게 하므로 결과적으로 전체적인 처리 속도가 개선되는 지는 확실하지 않다.



Fastswap은 작업이 요구하는 메모리 양을 최대로 하여 수행한다. `cgroup`과 `CFM`을 사용 함으로써, 노드의 작업이 사용하는 로컬 메모리를 리밸런싱 하고, 추가적인 작업을 할당할 수 있도록 할당 해제하낟. `cgroup`이 줄어들면 페이지는 원격으로 스왑 아웃된다. 일반적으로 줄어드는 비용은 작업을 처리할 때마다 줄어들고, 로컬에서 원격으로 메모리 이동의 네트워크의 처리량과 지연시간은 줄어든다. 



### 5.1 Job Degradation Profiles


![4](https://user-images.githubusercontent.com/56579239/189981187-5860253f-1d9a-46c2-a652-00d0a0ae59ab.png)


원격 메모리에서 로컬 메모리로 스왑이 응용 독립적으로 이루어질 때, 응용의 성능 저하를 경험한다. 위의 그림은 로컬 메모리 비율이 감소할 때 몇몇의 작업의 런타임이 증가하는 것을 보여준다.



원격 메모리를 사용하는 스케줄러는 모든 작업을 똑같이 처리할 수 없다. 작업 속도를 최적화하기 위해 작업 속도를 모델링할 수 있는 추가 정보가 필요하다. 그래서 논문에서는 로컬 메모리 비율이 다를 때 런타임을 측정한 `degradation profile`을 생성하여 사용한다. 



작업 프로필을 사용하는 것은 한계가 있다. 특히, 응용은 프로파일을 계산할 수 있도록 완료되어야 하며, 응용은 서로 다른 실행에서 원격 메모리를 사용할 때 유사한 성능 저하를 겪어야 합니다. ~~페이지 폴트 빈도를 사용하여 사전 계산된 프로필 대신 작업 속도 저하를 모델링하는 것이 가능할 수 있다.~~



### 5.2 Far Memory Scheduling Policies

Fastswap의 스케줄러는 메모리를 사용할 때를 제외하고 단순하고 보편적인 디자인을 사용한다. 

- 새로운 작업이 도착하면, 작업은 FIFO 방식의 `pending queue`에 더해진다. `peding queue`가 비어있지 않으면, 스케줄러는 작업을 온 순서대로 배치한다. 
- 각 작업에 대하여 스케줄러는 충분한 수의 코어와 메모리가 있는 노드를 찾기 위해 모든 노드를 탐색한다. 노드를 찾기 위한 평균 런타임을 개선하기 위해 노드를 무작위로 반복하고 작업은 발견된 첫 번째 노드에 배치한다. 
- 작업을 실행하기에 충분한 리소스가 있는 노드가 없으면 보류 중인 대기열에 그대로 둔다. 

*탐색하는 동안에 선점은 고려하지 않는다.*



작업을 스케줄링할 때, 스케줄러는 두 가지 결정이 필요하다.

1. **노드가 적합한가**

이를 결정하기 위해 메모리 정책이 제공하는 `fit` 함수를 사용한다. `fit` 함수는 작업을 수행할 수 있는 코어가 충분한 지 검사하는 것에서 시작한다. 그렇지 않으면 작업은 노드에 적합하지 않다고 판단한다. 충분한 코어가 이용가능하면, 휴리스틱을 사용하여 노드에서 로컬 메모리를 충분히 사용할 수 있는지 및 작업을 실행할 수 있는 충분한 사용 가능한 원거리 메모리가 남아 있는지 검사한다. 충분하다면 적합하다고 하는 반면, 충분하지 않으면 적합하지 않다고 판단한다.



2. **로컬 메모리를 얼마나 보낼 지**

이 양은 메모리 정책에 의해 제공되는 `rebalance` 함수를 통해 이루어진다. `rebalance` 함수는 노드에서 수행 중인 작업의 메모리 할당을 수정한다. 그래서 새로운 작업이 시작되기 전에 호출되어서 로컬 메모리의 공간을 확보하며, 작업이 끝나면 남은 작업의 순서대로 메모리를 다시 할당한다. `rebalance`는 원격 메모리도 필요하나 사용하지는 않는다.



다음은 `fit` 함수와 `rebalamce` 함수가 제공하는 메모리 정책이다.



<h4>Uniform policy</h4>

작업이 로컬의 이용 가능한 메모리보다 더 많은 메모리를 요구할 때, 이 정책은 모든 작업을 최소 비율 `α`까지 균일하게 축소한다. 예를 들어 `α=0.75`이면, 25%의 로컬 메모리를 원격 메모리의 작업을 위해 사용하는 것이다. 이 정책은 작업을 메모리 할당에 적합하고 리밸런싱하는 데에 최소 비율로 사용된다. 단순하기 때문에, 이 정책은 다른 작업들이 같은 비율로 줄어들었을 때 다르게 느려진다는 사실을 고려하지 않는다. 더하여, 같은 비율이더라도 작업이 사용하는 메모리 양에 따라 원격 메모리의 양이 다를 수 있다.



<h4>Variable policy</h4>

이 정책은 작업 당 최소 비율인 `Uniform`에 의해 향상 된다. Fastswap은 20% 둔화에 해당하는 작업에 대한 최소 비율을 선택했다. 20%는 작업 둔화와 생산량 개선 사이에서 절충점으로 결정한 것이다. 

`fit` 함수는 새로 수행될 작업을 포함하여 모든 작업에 대한 최소 비율 이상의 충분한 메모리 공간이 있으면 `true`를 반환한다. `rebalance` 함수는 최소 비율에 따라 작업 당 로컬 메모리 비율을 줄임으로써 메모리를 할당한다. 그래서 작업 당 최소 비율은 원격 메모리를 사용하는 것을 결정하는 것과 같다.

리밸런싱 작업은 유저에게 요구하는 작업 당 최소 비율을 기반으로 한다. 이 정책은 각 작업에 대해 로컬 메모리를 선형으로 확장하므로 성능 저하도 최소 비율까지 선형인 경우에 가장 좋은 성능을 발휘합니다.



<h4>Memory-time policy</h4>





### 5.3 Scheduler Implementation

스케줄러는 중앙 스케줄러와 노드별 데몬으로 구성된다. 둘 다 파이썬 1500줄에 구현됐으며, 중앙 스케줄러는 `§5.2`에 설명된 설계를 구현하고, `gRPC`를 사용하여 모든 데몬과 통신한다.

스케줄러가 작업을 데몬으로 보낼 때 데몬은 메모리 제한이 있는 `cgroup`을 만든다. 메모리 제한은 사용 중인 메모리 정책에 의해 정의된다. 메모리 제한이 작업에 필요한 메모리 양보다 작아서 메모리 사용량이 크게 증가할 수도 있다. 

스케줄러는 원격 메모리를 전혀 사용하지 않도록 구성할 수 있다. 이 경우 스케줄러는 먼 메모리를 사용하지 않는 구성을 데몬으로 전파한다.



## 6. Conclusion

Fastswap은 두 가지 트렌드를 초점으로 연구하였다.

1. 클러스터 워크로드의 메모리 요구 증가
2. 메모리 분산의 출현



그리고 두 가지 성능 향상을 보여주고 있는데, 이는 다음과 같다.

1. 원격 메모리를 사용하는 빠른 스왑 기술과 스케줄링 알고리즘
2. 메모리 집약적인 워크로드에서 소요 시간을 줄이는 몇 가지 시나리오
