# LRB

**Learning Relaxed Belady for Content  Distribution Network Caching**

<br>

> CDN
>
> Cache replacement algorithm
>
> Belady's algorithm

<br>

## 1. CDN

>  **Content Distribution Networks (CDNs)** deliver content through a network of caching servers to users to improve latency, bandwidth, and availability.
>
>  A CDN cache sits between **users** and **Wide-Area Networks (WANs)**. When the user requests content, the CDN server provides cached content.

<br>

  Whenever a user requests content that is not currently cached, the CDN must fetch this content across the **Internet Service Provider (ISPs)** and WANS. While CDNs are paid for the bytes delivered to users, they need to pay for the bandwidth required to fetch cache misses. These bandwidth costs constitute an increasingly large factor in the operational cost of large CDNs. CDNs are thus **seeking to minimize these costs**, which are typically measured as byte miss ratios, i.e., the fraction of bytes requested by users that are not served from cache.

<br>

  **The algorithm that decides which objects are cached** in each CDN server plays a key role in achieving a low byte miss ratio. Yet, the state-of-the-art algorithms used in CDN caching servers are heuristic-based variants of the **Least Recently Used (LRU)** algorithm. The drawback of heuristics-based algorithms is that they typically work well for some access patterns and poorly for others. And, still observe a large gap between the byte miss ratios of the state-of-the-art online cache replacement algorithms and **Belady's offline MIN algorithm** on a range of production traces.

<br>

## 2. LRB

  To bridge gap between LRU and Belady's algorithm, this paper presents a novel machine learning (ML) approach that is fundamentally different from previous approaches to cache replacement. Key approach is to **approximate Belady's MIN (oracle) algorithm, using machine learning to find objects to evict** based on past access patterns. 

<br>

  Belady's algorithm always evicts the object with the furthest next request. A **naive ML algorithm that imitates this behavior** would incur prohibitively **high computational cost**. To overcome this challenge, our key insight is that it is sufficient to approximate a **relaxed Belady algorithm** that evicts an object whose next request is **beyond a threshold** but not necessarily the farthest in the future.

<br>

It allows our system to **run predictions on a small sampled candidate set**. e.g., 64, which dramatically reduces computational cost. And, it allows our system to **quickly adapt to changes** in the workload by gathering training data that includes the critical examples of objects that relaxed Belady would have selected for replacement.

<br>

**Even with the insight of relaxed Belady, the design space** of potential ML architectures (features, model, loss function, etc.) is **enormous**. **Exploring this space** using end-to-end metrics like byte miss ratio is prohibitively time-consuming because they require full simulations that **take several hours** for a single configuration. 

<br>

To enable our exploration of the ML design space this paper introduces an eviction decision quality metric, the **good decision ratio**, that evaluates if the next request of an evicted object is beyond the Belady boundary. The good decision ratio allows us to **run a simulation only once** to gather training data, prediction data, and learn the Belady boundary. Then we can use it to quickly evaluate the quality of decisions made by an ML architecture **without running a full simulation**. We use the good decision ratio to explore the design space for components of our ML architecture including its features, model, prediction target, and loss function among others.

<br>

These concepts enable to design the Learning Relaxed Belady (LRB) cache, the first CDN cache that approximates Belady’s algorithm.

<br>

## 3. Belady's Algorithm

In order to approximate Belady’s MIN algorithm in the design of an ML-based cache, this paper introduces the relaxed Belady algorithm, Belady boundary, and good decision ratio.

<br>

### Relaxed Belady Algorithm

  It is difficult for an ML predictor to directly approximate Belady’s MIN algorithm for two reasons.

- The **cost** of running predictions for all objects in the cache can be prohibitively **high**.
- In order to find the object with the farthest next request, an ML predictor needs to **predict the time to next request of all objects in the cache accurately**.

<br>

![1](C:\Users\SH.C\OneDrive - UNIST\?? ??\paper\LRB\1.png)

*Figure 1: The relaxed Belady algorithm partitions objects into two sets based on their next request. The next requests of are beyond the threshold (Belady boundary).*

<br>

  To overcome these two challenges, we define the relaxed Belady algorithm, a variant of Belady’s MIN, that randomly **evicts an object whose next request is beyond a specific threshold**, as shown in Figure 1. The algorithm partitions the objects of a cache into two sets each time it needs to make an eviction decision.

- set 1: Objects whose next requests are **within the threshold**.
- set 2: Objects whose next requests are **beyond the threshold**.

If set 2 is not empty, the algorithm randomly evicts an object from this set. **If set 2 is empty**, the algorithm **reverts to the classical Belady** among object in set 1.

<br>

  The relaxed Belady algorithm has two important properties.

- If the **threshold is far**, its byte miss ratio will be **close to that of Belady’s MIN**.
- since the algorithm can evict any of the objects **in set 2**, not necessarily the object with farthest distance, **there will be many eviction choices** in the cache each time it needs to evict an object.

<br>

  These properties greatly reduce the requirements for an ML predictor. **Instead of predicting next requests for all objects** in the cache, the ML predictor **can run predictions on a small sample of candidates** in the cache for an eviction as long as the sample includes objects from set 2. This allows a dramatic reduction of computational cost. In addition, it reduces the required precision of the ML predictor. It only needs to find an object whose next request is beyond the threshold instead of the farthest. This greatly **reduces the memory overhead** when gathering training data: instead of having to track objects indefinitely, it is sufficient to track objects until they are re-requested or cross the threshold. 

<br>

  Shorter thresholds thus make the task of the ML predictor more tractable. While longer thresholds move the byte miss ratio of relaxed Belady closer to Belady’s MIN. It is thus **important to find the proper threshold**.

<br>

### Belady Boundary

  To **systematically choose a threshold** for the relaxed Belady algorithm, we introduce the **Belady boundary as the minimum of time to next request for all evicted objects** by Belady’s MIN algorithm. It is intuitively meaningful, Belady’s MIN kept all objects with a next request less than this boundary in the cache, but requires future information to compute.

<br>

  In practice, we assume that the Belady boundary is approximately stationary. This allows us to approximate the Belady boundary by computing the minimum of the next requests of all evicted objects by the Belady MIN algorithm during the machine learning warmup period. 

<br>

![2](C:\Users\SH.C\OneDrive - UNIST\?? ??\paper\LRB\2.png)

*Table 1: Comparison of the relaxed Belady algorithm to Belady MIN for the Wikipedia trace with different cache sizes.*

<br>

  Table 1 shows how the Belady boundary affects the byte miss ratio of relaxed Belady on the Wikipedia trace. We find that relaxed Belady applies random eviction to a set of objects, e.g., 19% for a 64 GB cache. While this Belady boundary enables efficient implementations, it comes at the cost of 9-13% more misses. Compared to the 25%–40% gap between stateof-the-art online algorithms and Belady’s MIN, this increase seems acceptable. 

<br>

  Next, show how to use the Belady boundary to establish a decision quality metric, which is used to make design decisions.

<br>

### Good Decision Ratio

To design an algorithm that makes better decisions we need to determine the quality of individual decisions. End-to-end metrics like byte miss ratio, however, reflect the aggregated quality of many decisions. When an algorithm has a byte miss ratio higher than Belady we know it made some bad decisions, but **we cannot determine which of its decisions were bad**. The individual misses that comprise byte miss ratio are similarly unhelpful because they are also the result of many earlier decisions.

<br>

 Our eviction decision metric is defined with respect to the relaxed Belady algorithm with the Belady boundary as its threshold. **Evicting an object is a good decision if the next request of the object is beyond the Belady boundary**. It is a bad decision if its next request is within the Belady boundary. 

<br>

  We find that an algorithm’s good decision ratio — i.e., # good decisions / # total eviction decisions — correlates strongly with the byte miss ratio it ultimately achieves. This metric plays a key part in the design of LRB.

<br>

## 4. Design

This section presents the design details of LRB, which uses ML to imitate the relaxed Belady algorithm. Accomplishing this requires simultaneously addressing two previously unsolved problems: 

- **How to design an ML approach that decreases byte miss ratio relative to state-of-the-art heuristics? **
- **How to build a practical system with that approach?**

<br>

  Each problem introduces several challenges in isolation, simultaneously addressing them additionally requires us to balance their often-competing goals. 

<br>

![3](C:\Users\SH.C\OneDrive - UNIST\?? ??\paper\LRB\3.png)

*Figure 2: General architecture that uses ML for caching.*

<br>

  Figure 2 presents a general architecture that uses ML to make eviction decisions. This paper identifies four key design issues:

**(1) Past information**: The first design issue is determining `how much and what past information to use`. More data improve training quality, but we need to limit the information in order to build a practical system, as higher memory overhead leads to less memory that can be used to cache objects. 

**(2) Training data**: The second design issue is `how to use past information for training`. As workloads vary over time the model must be periodically retrained on new data. Thus, a practical system must be able to dynamically generate training datasets with proper labels. 

**(3) ML architecture**: The third design issue is `selecting a machine learning architecture that makes good decisions`. This includes selecting features, the prediction target, and the loss function as well as how to translate predictions into eviction decisions. In addition, these decisions need to be compatible with available hardware resources to build a practical system.

 **(4) Eviction candidate selection**: The final design issue is `how to select eviction candidates`. Although an approximation of the relaxed Belady algorithm can evict any object whose next request is beyond the Belady boundary and there are many eviction choices, we still need a method to select a small set of candidates that includes such objects with a high probability. 

<br>

### Past information

<br>

  LRB keeps information about an object only when its most recent request is within the sliding memory window. The information within the sliding memory window is used for training and prediction. 



  Setting the size of the sliding memory window is important to the performance of LRB. If the sliding memory window is too short, LRB will not have enough training data to produce a good model and may not have the information it needs during prediction to make an accurate prediction. If the sliding memory window is too long, it may take too much space away from cached data. 



LRB uses each trace’s validation prefix to set the sliding memory window hyperparameter. For small cache sizes, the validation prefix is long enough to derive the “optimal” sliding memory window, which achieves the highest good decision ratio. For large cache sizes, we use a least-squares regression line fit to the relationship between small cache sizes and their optimal sliding memory window parameters. 



  Remark that, at the beginning of a trace (or during initial deployment), LRB requires training data to build an initial model. Thus, LRB implementation uses LRU as a fallback until sufficient training data is available

<br>

### Training data

<br>

  Acquiring training data for our problem is challenging because the features and corresponding label exist at widely disparate times. Consider an object that is requested once and then not requested again until 5 hours later. The features of the object exist and vary at all times in the 5-hour range. The label—i.e., what we want to predict—does not exist until the end of that range, when we know the “future” by waiting until it is the present. To address the time disparity, LRB decouples generation of unlabeled training data from labeling that data.

<br>

**Unlabeled training data generation**

<br>

  To generate unlabeled training data LRB periodically takes a random sample of objects in the sliding memory window and then records the current features of those objects. We choose to randomly sample over objects instead of over requests to avoid biasing the training data towards popular objects with many requests. Such popular objects should be represented in the training data so the model learns not to evict them. Training data for less popular objects, however, is more important because they include the objects beyond the Belady boundary—the good eviction decisions we want our model to learn. We choose to randomly sample over all objects in the sliding memory window instead of only those currently in the cache as cached objects are similarly biased.

<br>

**Labeling training data**

<br>

LRB uses two methods for assigning labels to training data. The first is to wait until an object is requested again. When this happens, we know the “future” and use that to determine the label. Some objects, however, will not be requested until far—e.g., 5 days—in the future.

<br>

  Waiting until such objects are requested again would introduce many problems. First, it would require excessive memory overhead as we maintain features for many objects that were requested a potentially very long time ago. Second, it would make some of the training data excessively old, e.g., 5 days old. Finally, it would never include training data for objects that are never requested again—which are a significant portion of the good decisions we want our method to learn. 

<br>

  LRB’s second method for labeling training data avoids these problems by leveraging an insight related to the Belady boundary: all objects that are not requested again for at least a boundary amount of time are equivalent good eviction decisions. Thus, once the time since last request for an object exceeds the Belady boundary we can safely label it. LRB uses this second labeling method when an object falls out of the sliding memory window

<br>

### ML Architecture

<br>

### Eviction Candidate Selection

<br>

  LRB randomly samples cached objects to gain eviction candidates and runs a batch prediction for all candidates. LRB evicts the candidate whose predicted next request distance is the longest. 



  determine the choice for our random sample size— 64 samples—using the good decision ratio. study finds that 64 samples are past the point of diminishing returns, and thus choosing it does not disadvantage our ML architecture. It is also still low enough for low overhead—prediction on 64 samples takes LRB only 30 µs.

<br>

### Putting all Together

<br>

![]()

*Figure 3: s*

<br>

  Putting our design decisions together with the general architecture (Figure 4) from the beginning of the section, we have the complete design of LRB as shown in Figure 3. 

<br>

  LRB learns from the requested objects in a sliding memory window whose length approximates the Belady boundary. The features (deltas, EDCs, static) of these objects are stored in a compact data structure that is updated as new requests arrive, moving the sliding memory window forward. 

<br>

  A sampling process continuously samples data from this data structure, generating an unlabeled dataset. A separate labeling process continuously labels that data. When the labeled dataset is full (128K examples), LRB starts training a GBM model, and empties the labeled dataset. After that, whenever the labeled dataset is full again, LRB repeats the process and replaces the old model with the new one. If a current request is a cache miss and needs to evict an object, LRB randomly draws k = 64 eviction candidates and runs GBM predictions on them. LRB evict the candidate with the farthest predicted next access time

<br>

## 5. Conclusion

  The key advantage of using ML to approximate Belady’s MIN algorithm over access-pattern specific or heuristicsbased approaches is that it can intelligently make cache eviction decisions based on any access pattern.

<br>

  More importantly, This paper has introduced the relaxed Belady algorithm, Belady boundary, and good decision ratio as an eviction quality metric, which has enabled to take a fundamentally new approach to caching that approximates Belady’s MIN algorithm. These concepts can benefit others in the future.

<br>

  LRB’s implementation is practical and deployable by replacing the caching component of a production CDN caching system with LRB. Our experiments show that its throughput and latency are on par with the native implementation. LRB requires neither GPUs nor accelerators and, in fact, its additional CPU and memory overheads are moderate and within the constraints of today’s CDN server hardware. This deployable design is enabled by key design decisions including our feature selection, sliding memory window, training data selection, and choice of a lightweight machine learning model.





